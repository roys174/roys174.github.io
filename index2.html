<!-- !DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd"> -->
<!DOCTYPE html>
<html>
 
<head>
<meta name="viewport" content="width=device-width">

<script type="text/javascript" src="import.js"></script> 
<!--link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">-->

    


<link href='http://fonts.googleapis.com/css?family=Cabin:600|Nunito:400,300' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="styles2.css" type="text/css">
<meta name="keywords" content="Roy Schwartz, רועי שוורץ">
<meta charset="UTF-8">

<script type="text/javascript" src="jquery.js"></script>
<title>Roy Schwartz's Homepage, רועי שוורץ</title>

<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22481028-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

</head>

<body>
<hr>

<a name="top"></a>

<div style="height: 230px">
   <div style="top: 100px; position: absolute;" class=page_titles>Roy Schwartz</div>
   <img class="fluidimage" align="right" SRC="index_files/roy_schwartz.jpg" style="max-height:100%;max-width:100%;"/>
</div>

<hr>
<p>
|
<a href="#short-bio"> Short Bio</a>
|
<a href="#publications"> Publications</a>
|
<a href="#talks"> Talks </a>
|
<a href="#reviewing">Professional Activities</a>
| 
<a href="#code">Software and Resources</a>
| 
<a href="#teaching">Teaching</a>
|
<a href="#contact_info">Contact Info</a>
|

<hr>

<p><a name=short-bio></a>
<h2 class=h2_style>Short Bio</h2>

<div style="text-align:justify">
<p> I am a postdoctoral researcher at <a href="http://www.cs.washington.edu/" target="_blank">the computer science and engineering department</a> at <a href="http://www.washington.edu/" target="_blank">The University of Washington</a>, working with <script>document.write(NOAH)</script> and at <a href="http://allenai.org/index.html" target="_blank">the Allen institute for Artificial intelligence</a>.
I completed my Ph.D. at <a href="http://www.cs.huji.ac.il" target="_blank">the School of Computer Science and Engineering</a>
of <a href="http://www.huji.ac.il/" target="_blank">The Hebrew University of Jerusalem</a>, where I worked with <a href="http://www.cs.huji.ac.il/~arir" target="_blank">Prof. Ari Rappoport</a>.
My main research area is <b>semantic representation</b>. 
</p>
<p>In 2011, I graduated my masters degree (<b>magna cum laude</b>) in computer science, under the supervision of 
Prof. Ari Rappoport [<script>URL(HOME,'papers/roy_schwartz_thesis_final.pdf','dissertation')</script>]. 
Prior to that, I studied computer science and cognitive sciences at the Hebrew University, and
completed my B.Sc. (<b>magna cum laude</b>) in 2008. 
I was a member of the Amirim program for outstanding undergraduate students. 
In 2004-2005, I was a software engineer at <a href="http://www.checkpoint.com/" target="_blank">Check Point Ltd.</a>
<p>
</p>


</div>

<!-- <br>I collaborate with <script>document.write(OMRI)</script>
and <a href="http://ie.technion.ac.il/~roiri/" target="_blank">Roi Reichart</a>. <br><br> -->


<hr size=2 width="100%" align=center>

<p>
|
<a href="#top">Top</a>
|
<a href="#news">News</a>
|
<a href="#publications">Publications</a>
|
<a href="#talks"> Talks</a>
|
<a href="#reviewing">Professional Activities</a>
| 
<a href="#code">Software and Resources</a>
| 
<a href="#teaching">Teaching</a>
|
<a href="#contact_info">Contact Info</a>
|

<hr size=2 width="100%" align=center>

<h2 class='h2_style'><a name=news></a>News</h2>

<span class="news">
<ul>
<li> 
<b><span style='color:blue'>Two papers</span></b> accepted to NAACL 2018!
</li>
</ul>
</span>


<hr size=2 width="100%" align=center>
|
<a href="#top"> Top</a>
|
<a href="#short-bio"> Short Bio</a>
|
<a href="#publications">Publications</a>
|
<a href="#talks"> Talks</a>
|
<a href="#reviewing">Professional Activities</a>
| 
<a href="#code">Software and Resources</a>
| 
<a href="#teaching">Teaching</a>
|
<a href="#contact_info">Contact Info</a>
|

<hr size=2 width="100%" align=center>

<p><a name=publications></a>

<!--<h2 class='h2_style'>Publications (on <a <a href="https://www.semanticscholar.org/author/Roy-Schwartz/1702335" target="_blank">semantic scholar</a>, <a href="http://scholar.google.com/citations?user=wvfWo9IAAAAJ&amp;hl=en" target="_blank">google scholar</a>)</h2>-->
<h2 class='h2_style'>Publications (on <a href="http://scholar.google.com/citations?user=wvfWo9IAAAAJ&amp;hl=en" target="_blank">google scholar</a>)</h2>

<span class="publications">

<script>YEAR(2018)</script>
<ul>
<li>
<i><span style='color:blue'><b>[NEW]</b></span></i>	
<i>A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications</i>
<br>
<i><script>document.write(DONGYEOP+", "+WALEED+", "+BHAVANA+", Madeleine van Zuylen, Sebastian Kohlmeier, "+ED+" and "+ME)</script></i><br>
<i>To appear in the proceedings of <a href="http://naacl2018.org/" target="_blank">NAACL 2018</a></i>
[<a href="#" onclick="$('#peeread_abstract').toggle();return false;">abstract</a>]
<!--[<script>URL(HOME,'papers/language_constraint/language_constraint_poster.pdf','poster')</script>]-->
[<script>URL(HOME,'papers/peeread/peeread.bib','bib')</script>]
<!--[<script>URL('','https://github.com/roys174/writing_style','data', "style='color:blue'")</script>]-->
<div id="peeread_abstract" class="publications" style="display:none;">
Peer reviewing is a central component in the scientific publishing process.
We present the first public dataset of scientific peer reviews available for research purposes (PeerRead v1) providing an opportunity to study this important artifact.
The dataset consists of 14K paper drafts and the corresponding accept/reject decisions in top-tier venues including ACL, NIPS and ICLR. 
The dataset also includes 8.7K textual peer reviews written by experts for a subset of the papers.
We describe the data collection process and report  interesting observed phenomena in the peer reviews.
We also propose two novel NLP tasks based on this dataset and provide simple baseline models.
In the first task, we show that simple models can predict whether a paper is accepted with up to 21% error reduction compared to the majority baseline.
In the second task, we predict the numerical scores of review aspects and show that simple models can outperform the mean baseline for aspects with high variance such as 'originality' and 'impact'.
</li>
<li>
<i><span style='color:blue'><b>[NEW]</b></span></i>	
<i>Annotation Artifacts in Natural Language Inference Data</i>
<br>
<i><script>document.write(SUCHIN+", "+SWABHA+", "+OMER+", "+ME+", "+SAMB+" and "+NOAH)</script></i><br>
<i>To appear in the proceedings of <a href="http://naacl2018.org/" target="_blank">NAACL 2018</a></i>
[<a href="#" onclick="$('#artifacts_abstract').toggle();return false;">abstract</a>]
<!--[<script>URL(HOME,'papers/language_constraint/language_constraint_poster.pdf','poster')</script>]-->
[<script>URL(HOME,'papers/artifacts/artifacts.bib','bib')</script>]
<!--[<script>URL('','https://github.com/roys174/writing_style','data', "style='color:blue'")</script>]-->
<div id="artifcats_abstract" class="publications" style="display:none;">
Large-scale datasets for natural language inference are created by presenting crowd workers with a sentence (premise), and asking them to generate three new sentences (hypotheses) that it entails, contradicts, or is logically neutral with respect to. 
We show that, in a significant portion of such data, this protocol leaves clues that make it possible to identify the label by looking only at the hypothesis, without observing the premise. 
Specifically, we show that a simple text categorization model can correctly classify the hypothesis alone in about 67\% of SNLI (Bowman et al., 2015) and 53\% of MultiNLI (Williams et al., 2018).
Our analysis reveals that specific linguistic phenomena such as negation and vagueness are highly correlated with certain inference classes. 
Our findings suggest that the success of natural language inference models to date has been overestimated, and that the task remains a hard open problem. 
</li>

<br>
<script>YEAR(2017)</script>


<ul>
<li>
<i>The Effect of Different Writing Tasks on Linguistic Style: A Case Study of the ROC Story Cloze Task</i>
<br>
<i><script>document.write(ME+", "+MAARTEN+", "+YANNIS+", "+LI+", "+YEJIN+" and "+NOAH)</script></i><br>
<i>In proceedings of <a href="http://www.conll.org/2017" target="_blank">CoNLL 2017</a></i>
<br>
<i>
<script>PDF('http://arxiv.org/abs/1702.01841')</script>
<!--[<a href="http://arxiv.org/abs/1702.01841" onClick="_gaq.push(['_trackPageview', 'http://arxiv.org/abs/1702.01841']);" target="_blank">pdf</a>]-->
[<a href="#" onclick="$('#language_constraint_abstract').toggle();return false;">abstract</a>]
[<script>URL(HOME,'papers/language_constraint/language_constraint_poster.pdf','poster')</script>]
[<script>URL(HOME,'papers/language_constraint/language_constraint.bib','bib')</script>]
[<script>URL('','https://github.com/roys174/writing_style','code', "style='color:blue'")</script>]
[<script>URL('','https://soundcloud.com/nlp-highlights/32-the-effect-of-different-writing-tasks-on-linguistic-style-with-roy-schwartz','podcast interview', "style='color:green'; target='_blank'")</script>]
<div id="language_constraint_abstract" class="publications" style="display:none;">
A writer's style depends not just on personal traits but also on her intent and mental state. In this paper, we show how variants of the same writing task can lead to measurable differences in writing style. We present a case study based on the story cloze task (Mostafazadeh et al., 2016a), where annotators were assigned similar writing tasks with different constraints: (1) writing an entire story, (2) adding a story ending for a given story context, and (3) adding an incoherent ending to a story. We show that a simple linear classifier informed by stylistic features is able to successfully distinguish among the three cases, without even looking at the story context. In addition, combining our stylistic features with language model predictions reaches state of the art performance on the story cloze challenge. Our results demonstrate that different task framings can dramatically affect the way people write.
</div>
</i>
</li>
<li>
<i><span style='color:blue'><b>[NEW]</b></span></i>	
<i>
<i>Automatic selection of context configurations for improved (and fast) class-specific word representations</i>
<br>
<a href='https://sites.google.com/site/ivanvulic/' target="_blank")>Ivan Vulić</a>, <script>document.write(ME+", "+ARI+", "+ROI)</script> and <a href="http://www.cl.cam.ac.uk/~alk23/" target="_blank">Anna Korhonen</a><br> 
In proceedings of <a href="http://www.conll.org/2017" target="_blank">CoNLL 2017</a>
<br>
[<a href="http://arxiv.org/abs/1608.05528" onClick="_gaq.push(['_trackPageview', 'http://arxiv.org/abs/1608.05528']);" target="_blank">pdf</a>]
[<a href="#" onclick="$('#context_config_abstract').toggle();return false;">abstract</a>]
[<script>URL(HOME,'papers/context_config/context_config_slides.pdf','slides')</script>]
[<script>URL(HOME,'papers/context_config/context_config.bib','bib')</script>]
<div id="context_config_abstract" class="publications" style="display:none;"> 
<i>
This paper is concerned with identifying contexts useful for training word representation models for different word classes such as adjectives (A), verbs (V), and nouns (N). We introduce a simple yet effective framework for an automatic selection of class-specific context configurations. We construct a context configuration space based on universal dependency relations between words, and efficiently search this space with an adapted beam search algorithm. In word similarity tasks for each word class, we show that our framework is both effective and efficient. Particularly, it improves the Spearman's rho correlation with human scores on SimLex-999 over the best previously proposed class-specific contexts by 6 (A), 6 (V) and 5 (N) rho points. With our selected context configurations, we train on only 14% (A), 26.2% (V), and 33.6% (N) of all dependency-based contexts, resulting in a reduced training time. Our results generalise: we show that the configurations our algorithm learns for one English training setup outperform previously proposed context types in another training setup for English. Moreover, basing the configuration space on universal dependencies, it is possible to transfer the learned configurations to German and Italian. We also demonstrate improved per-class results over other context types in these two languages.
</i>
</li>


<li>
<i>Story Cloze Task: UW NLP System</i>
<br>
<script>document.write(ME+", "+MAARTEN+", "+YANNIS+", "+LI+", "+YEJIN+" and "+NOAH)</script><br> <a href=http://cs.rochester.edu/nlp/rocstories/LSDSem17/ target=none>LSDSem 2017 shared task</a><span style="color:red"><b> [Best performing system]</b></span>
<br>
[<a href="papers/language_constraint/lsdsem_uw_nlp.pdf" onClick="_gaq.push(['_trackPageview', 'papers/language_constraint/shared_task_paper_camera_ready.pdf']);" target="_blank">pdf</a>]
[<a href="#" onclick="$('#lsdsem_uw_nlp').toggle();return false;">abstract</a>]
[<script>URL(HOME,'papers/language_constraint/lsdsem_uw_nlp_slides.pdf','slides')</script>]
[<script>URL(HOME,'papers/language_constraint/lsdsem_uw_nlp_poster.pdf','poster')</script>]
[<script>URL(HOME,'papers/language_constraint/lsdsem_uw_nlp.bib','bib')</script>]
<div id="lsdsem_uw_nlp" class="publications" style="display:none;">
<i>
This paper describes University of Washington NLP's submission for the Linking Models of Lexical, Sentential and Discourse-level Semantics (LSDSem 2017) shared task---the Story Cloze Task. Our system is a linear classifier with a variety of features, including both the scores of a neural language model and style features. We report 75.2% accuracy on the task. A further discussion of our results can be found in Schwartz et al. (2017).

</i>
</div>
</li>
</ul>

<script>YEAR(2016)</script>


<ul>
<li> 
<i> Pattern-based methods for Improved Lexical Semantics and Word Embeddings</i>
<br>
<script>document.write(ME)</script><br> 
Ph.D. dissertation<br>
[<script>URL(HOME,'papers/roy_schwartz_phd_dissertation.pdf','pdf')</script>]
[<script>URL(HOME,'papers/roy_schwartz_phd_dissertation.bib','bib')</script>]
<li>
<i>
<script>URL(HOME,'papers/sp_sg/sp_sg.html','Symmetric Patterns and Coordinations: Fast and Enhanced Representations of Verbs and Adjectives')</script></i>
<!--<b><i>Symmetric Patterns and Coordinations: Fast and Enhanced Representations of Verbs and Adjectives</i></b>-->
<br>
<script>document.write(ME+", "+ROI+" and "+ARI)</script><br> 
In proceedings of <a href='http://naacl.org/naacl-hlt-2016/' target="_blank">NAACL 2016</a> (short paper)
<br>
[<script>URL(HOME,'papers/sp_sg/sp_sg_naacl_camera_ready.pdf','pdf')</script>]
[<a href="#" onclick="$('#sp_sg_abstract').toggle();return false;">abstract</a>]
[<script>URL(HOME,'papers/sp_sg/sp_sg_naacl_poster.pdf','poster')</script>]
[<script>URL(HOME,'papers/sp_sg/sp_sg.bib','bib')</script>]
[<script>URL(HOME,'papers/sp_sg/sp_sg.html','code and embeddings', "style='color:green'")</script>]
<!--[<a href="http://techtalks.tv/talks/symmetric-pattern-based-word-embeddings-for-improved-word-similarity-prediction/61868/" target="_blank"><span style='color:purple'>video</span></a>]-->
<div id="sp_sg_abstract" class="publications" style="display:none;"> 
<i>
State-of-the-art word embeddings, which are often trained on bag-of-words (BOW) contexts, provide a high quality representation of aspects of the semantics of nouns. 
However, their quality decreases substantially for the task of verb similarity prediction. 
In this paper we show that using symmetric pattern contexts (SPs, e.g., ``X and Y'') 
improves word2vec verb similarity performance by up to 15% and is also instrumental in adjective similarity prediction. 
The unsupervised SP contexts are even superior to a variety of dependency contexts extracted using a supervised dependency parser. 
Moreover, we observe that SPs and dependency coordination contexts (Coor) capture a similar type of information, 
and demonstrate that Coor contexts are superior to other dependency contexts including the set of all dependency contexts, 
although they are still inferior to SPs.
Finally, there are substantially fewer SP contexts compared to alternative representations,
leading to a massive reduction in training time. 
On an 8G words corpus and a 32 core machine, the SP model trains in 11 minutes,
compared to 5 and 11 hours with BOW and all dependency contexts, respectively.
</i>
</li>

</li>
</ul>

<script>YEAR(2015)</script>

<ul>
<li>
<i><script>URL(HOME,'papers/sp_embeddings/sp_embeddings.html','Symmetric Pattern Based Word Embeddings for Improved Word Similarity Prediction')</script></i>

<br>
<script>document.write(ME+", "+ROI+" and "+ARI)</script><br> 
In proceedings of <a href='http://www.conll.org/2015' target="_blank">CoNLL 2015</a> (long paper)

<br>
[<script>URL(HOME,'papers/sp_embeddings/sp_embeddings_conll.pdf','pdf')</script>]
[<a href="#" onclick="$('#sp_embeddings_abstract').toggle();return false;">abstract</a>]
[<script>URL(HOME,'papers/sp_embeddings/sp_embeddings_slides.pdf','slides')</script>]
[<script>URL(HOME,'papers/sp_embeddings/sp_embeddings.bib','bib')</script>]
[<script>URL(HOME,'papers/sp_embeddings/sp_embeddings.html','code and embeddings', "style='color:green'")</script>]
[<script>URL(HOME,'papers/sp_embeddings/sp_embeddings.html','Pattern extraction code', "style='color:blue'")</script>]
[<a href="http://techtalks.tv/talks/symmetric-pattern-based-word-embeddings-for-improved-word-similarity-prediction/61868/" target="_blank"><span style='color:purple'>video</span></a>]
<div id="sp_embeddings_abstract" class="publications" style="display:none;"> 
<i>We present a novel word level vector representation based on symmetric patterns (SPs). For this aim we automatically acquire SPs (e.g., "X and Y") from a large corpus of plain text, and generate vectors where each coordinate represents the co-occurrence in SPs of the represented word with another word of the vocabulary. Our representation has three advantages over existing alternatives: First, being based on symmetric word relationships, it is highly suitable for word similarity prediction. Particularly, on the SimLex999 word similarity dataset, our model achieves a Spearman's &#961; score of 0.517, compared to 0.462 of the state-of-the-art word2vec model. Interestingly, our model performs exceptionally well on verbs, outperforming state-of-the-art baselines by 20.2&#x2012;41.5%. Second, pattern features can be adapted to the needs of a target NLP application. For example, we show that we can easily control whether the embeddings derived from SPs deem antonym pairs (e.g. (big,small)) as similar or dissimilar, an important distinction for tasks such as word classification and sentiment analysis. Finally, we show that a simple combination of the word similarity scores generated by our method and by word2vec results in a superior predictive power over that of each individual model, scoring as high as 0.563 in Spearman's &#961; on SimLex999. This emphasizes the differences between the signals captured by each of the models.</i>
</li>


<li>
<i><script>URL(HOME,'papers/semantics_from_text/semantics_from_text.html','How Well Do Distributional Models Capture Different Types of Semantic Knowledge?')</script></i>


<br>
Dana Rubinstein, Effi Levi, <script>document.write(ME+" and "+ARI)</script><br> 
In proceedings of <a href='http://www.acl2015.org/' target="_blank">ACL 2015</a> (short paper)
<br>
[<script>URL(HOME,'papers/semantics_from_text/semantics_from_text.pdf','pdf')</script>]

[<a href="#" onclick="$('#semantics_from_text_abstract').toggle();return false;">abstract</a>]
[<script>URL(HOME,'papers/semantics_from_text/semantics_from_text_poster.pdf','poster')</script>]
[<script>URL(HOME,'papers/semantics_from_text/semantics_from_text.bib','bib')</script>]
<div id="semantics_from_text_abstract" class="publications" style="display:none;"> 
<i>
In recent years, distributional models (DMs) have shown great success in representing lexical semantics. 
In this work we show that the extent to which DMs represent semantic knowledge is highly dependent on the type of knowledge. 
We pose the task of predicting properties of concrete nouns in a supervised setting, and compare between learning taxonomic properties (e.g., animacy) and attributive properties (e.g., size, color). 
We employ four state-of-the-art DMs as sources of feature representation for this task, and show that they all yield poor results when tested on attributive properties, achieving no more than an average F-score of 0.37 in the binary property prediction task, compared to 0.73 on taxonomic properties. Our results suggest that the distributional hypothesis may not be equally applicable to all types of semantic information.
</i>

<i></i>
</div>
</li>
</ul>

<script>YEAR(2014)</script>

<ul>
<li>
<i><script>URL(HOME,'papers/coarse_grained/coarse_grained.html','Minimally Supervised Classification to Semantic Categories using Automatically Acquired Symmetric Patterns')</script></i>

<br>
<script>document.write(ME+", "+ROI+" and "+ARI)</script><br> 
In proceedings of <a href='http://www.coling-2014.org/' target="_blank">COLING 2014</a> (long paper)
<br>

[<script>URL(HOME,'papers/coarse_grained/coarse_grained_camera_ready.pdf','pdf')</script>]
[<a href="#" onclick="$('#coarse_grained_abstract').toggle();return false;">abstract</a>]
[<script>URL(HOME,'papers/coarse_grained/coarse_grained_slides.pdf','slides')</script>]
[<script>URL(HOME,'papers/coarse_grained/coarse_grained.bib','bib')</script>]

<div id="coarse_grained_abstract" class="publications" style="display:none;"> 
<i>Classifying nouns into semantic categories (e.g., animals, food) is an important line of research in both cognitive science and natural language processing. We present a minimally supervised model for noun classification, which uses symmetric patterns (e.g., "X and Y") and an iterative variant of the k-Nearest Neighbors algorithm. Unlike most previous works, we do not use a predefined set of symmetric patterns, but extract them automatically from plain text, in an unsupervised manner. We experiment with four semantic categories and show that symmetric patterns constitute much better classification features compared to leading word embedding methods. We further demonstrate that our simple k-Nearest Neighbors algorithm outperforms two state-of-the-art label propagation alternatives for this task. In experiments, our model obtains 82%-94% accuracy using as few as four labeled examples per category, emphasizing the effectiveness of simple search and representation techniques for this task.</i>

</div>
</li>
</ul>


<script>YEAR(2013)</script>
<ul>
<li>
<i><script>URL(HOME,'papers/twitter_authorship/twitter_authorship.html','Authorship Attribution of Micro-Messages')</script></i>

<br>
<script>document.write(ME)</script>, <a href="http://people.seas.harvard.edu/~orentsur" target="_blank">Oren Tsur</a>, <script>document.write(ARI)</script> and <a
href="http://u.cs.biu.ac.il/~koppel/" target="_blank">Moshe Koppel</a><br> 
In proceedings of <a href='http://hum.csse.unimelb.edu.au/emnlp2013/' target="_blank">EMNLP 2013</a> (long paper)
<br>
[<script>URL(HOME,'papers/twitter_authorship/twitter_authorship_emnlp4.pdf','pdf')</script>]
[<a href="#" onclick="$('#twitter_authorship_abstract').toggle();return false;">abstract</a>] 
[<script>URL(HOME,'papers/twitter_authorship/twitter_authorship_slides.pdf','slides')</script>]
[<script>URL(HOME,'papers/twitter_authorship/twitter_authorship.bib','bib')</script>]
<a style="display:none" target="_blank">page</a>
<div id="twitter_authorship_abstract" class="publications" style="display:none;"> 
<i>Work on authorship attribution has traditionally focused on long texts. In this work, we tackle the question of whether the author of a very short text can be successfully identified. We use Twitter as an experimental testbed. We introduce the concept of an author's unique "signature", and show that such signatures are typical of many authors when writing very short texts. We also present a new authorship attribution feature ("flexible patterns") and demonstrate a significant improvement over our baselines. Our results show that the author of a single tweet can be identified with good accuracy in an array of flavors of the authorship attribution task. </i>
</div>
</li>
</ul>

<script>YEAR(2012)</script><ul>
	
<li>
<i><script>URL(HOME,'papers/learnable/learnable.html','Learnability-based Syntactic Annotation Design')</script></i>
<br>
<script>document.write(ME+", "+OMRI+" and "+ARI)</script><br> 
In proceedings of <a href="http://www.coling2012-iitb.org/" target="_blank">COLING 2012</a> (long paper)
<br>
[<script>URL(HOME,'papers/learnable/learnable_coling_camera_ready.pdf','pdf')</script>]
[<a href="#" onclick="$('#learnable_abstract').toggle();return false;">abstract</a>] 
[<script>URL(HOME,'papers/learnable/learnable_coling_slides.pdf','slides')</script>]
[<script>URL(HOME,'papers/learnable/learnable_coling.bib','bib')</script>]
[<script>URL(HOME,'software/learnable.html','code', "style='color:blue'")</script>]
<a style="display:none" target="_blank">page</a>
<div id="learnable_abstract" class="publications" style="display:none;"> 
<i>There is often more than one way to represent syntactic structures, even within a given formalism. Selecting one representation over another may affect parsing performance. Therefore, selecting between alternative syntactic  representations (henceforth, syntactic selection) is an essential step in designing an annotation scheme. We present a methodology for syntactic selection and apply it to six central dependency structures. Our methodology compares pairs of annotation schemes that differ in the annotation of a single structure. It selects the more learnable scheme, namely the one that can be better learned using statistical parsers. We find that in three of the structures, one annotation is unequivocally better than the alternatives. Our results are consistent over various settings involving five parsers and two definitions of learnability. Furthermore, we show that the learnability gains incurred by our selections are both considerable (error reductions of up to 19.8%) and additive. The contribution of this work is in demonstrating that syntactic selection has a substantial and predictable effect on parsing performance, and showing that this effect can be effectively used in designing syntactic annotation schemes.</i>
</div></li>
</ul>


<script>YEAR(2011)</script>
<ul>
<li><i>
<script>URL(HOME,'papers/ned/ned.html','Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation')</script>
</i><br>
<script>document.write(ME+", "+OMRI+", "+ROI+" and "+ARI)</script><br>
In proceedings of <a href="http://www.acl2011.org/" target="_blank">ACL 2011</a> (long paper) 
<br>
[<script>URL(HOME,'papers/ned/ned_camera_ready.pdf','pdf')</script>]
[<a href="#" onclick="$('#ned_abstract').toggle();return false;">abstract</a>] 
[<script>URL(HOME,'papers/ned/ned_acl_slides.pdf','slides')</script>]
[<script>URL(HOME,'papers/ned/ned.bib','bib')</script>]
[<script>URL(HOME,'software/ned.html','code', "style='color:blue'")</script>]

<div id="ned_abstract" class="publications" style="display:none;"> 
<i>Dependency parsing is a central NLP task. In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations. We show that for three leading unsupervised parsers (Klein and Manning, 2004; Cohen and Smith, 2009; Spitkovsky et al., 2010a), a small set of parameters can be found whose modification yields a significant improvement in standard evaluation measures. These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation. Therefore, the standard evaluation does not provide a true indication of algorithm quality. We present a new measure, Neutral Edge Direction (NED), and show that it greatly reduces this undesired phenomenon.</i>
</div></li>

</ul>

</span>

<hr size=2 width="100%" align=center>
|
<a href="#top"> Top</a>
|
<a href="#short-bio"> Short Bio</a>
|
<a href="#news">News</a>
|
<a href="#talks">Talks</a>
|
<a href="#reviewing">Professional Activities</a>
| 
<a href="#code">Software and Resources</a>
| 
<a href="#teaching">Teaching</a>
|
<a href="#contact_info">Contact Info</a>
|

<hr size=2 width="100%" align=center>

<h2 class='h2_style'><a name=talks></a>Talks</h2>

<span class="talks">
<ul>
	<li>
	<i>
	<script>URL(HOME,'talks/2016_02_pattern_solutions.pdf','Pattern-based Solutions to Limitations of Leading Word Embeddings')</script>
	</i>
<!--				</a>-->
		<br>
		Intel Inc. Yakum, Research talk (03/2016)
		<br>
		University of Pennsylvania, <a href="https://pricelab.sas.upenn.edu/clunch" target="_blank">CLunch computational linguistics seminar</a> (02/2016)
		<br>
		Johns Hopkins University, NLP seminar (02/2016)
		<br>
		University of Washington, <a href="https://www.cs.washington.edu/node/12019" target="_blank">NLP seminar</a> (02/2016)		
	</li>
<li>
	<i>
	<script>URL(HOME,'talks/ibm_2015_09.pdf','Word Similarity via Symmetric Patterns')</script>
	</i>
	<br>
IBM Research Tel Aviv, Machine Learning and Data Mining Group Seminar (09/2015)</li>

<li>
	<i>
	<script>URL(HOME,'talks/cognition_symposion_2015_02.pdf','Semantic Knowledge Acquisition using Frequency Based Patterns')</script>
	</i><br>
The Catalonia-Israel Symposium on<a href="https://scholars.huji.ac.il/llcc/event/catalonia-israel-symposium-lexical-semantics-and-grammatical-structure-event" target="_blank"> Lexical Semantics and Grammatical Structure</a> (02/2015)</li>

<li>
	<i>
	<script>URL(HOME,'talks/learning_club_2014_12.pdf','Acquiring Semantic Knowledge using Patterns')</script>
	</i><br>
Hebrew University, <a href="http://www.cs.huji.ac.il/site/?i=LearningClub" target="_blank">CS Learning Semanir</a> (12/2014)</li>
<li>

<i>
<script>URL(HOME,'talks/twitter_authorship_slides_icri_05_2014.pdf','Identifying Authorships of very Short Texts using Flexible Patterns')</script>
</i><br>
Intel Inc. Haifa, <a href="http://icri-ci.technion.ac.il/events-2/presentation-files-icri-ci-retreat-13-14-may-2014/" target="_blank">ICRI-CI Retreat</a> (05/2014)</li>
<li>
<i>
<script>URL(HOME,'talks/semantics_slides_10_2013.pdf','Semantic Representation using Flexible Patterns')</script>
</i><br>
Berkeley, Natural Language Processing Group Seminar (10/2013)<br>
Stanford, <a href='http://nlp.stanford.edu/read/' target="_blank">Natural Language Processing Group Seminar</a> (10/2013)<br>
USC Information Sciences Institute, <a href='http://nlg.isi.edu/nl-seminar/' target="_blank">Natural Language Processing Group Seminar</a> (10/2013)<br>
Twitter Inc., Technological Talk (10/2013)<br>
Intel Inc. Santa Clara, Natural Language Processing Group Seminar (10/2013)<br>
IBM Research Tel Aviv, Machine Learning and Data Mining Group Seminar (10/2013)</li>

<!--<!--Seminars or Group meetings at <a href='http://nlp.cs.berkeley.edu/' target="_blank">Berkeley</a>, <!--a href='https://www.research.ibm.com/haifa/seminars/index.shtml' target="_blank">IBM Research/a>, Intel labs, <a href='http://nlg.isi.edu/nl-seminar/' target="_blank">ISI</a>, <a href='http://nlp.stanford.edu/read/' target="_blank">Stanford</a> and Twitter, October 2013-->


<li>
<i>
<script>URL(HOME,'talks/ned_iscol_06_2011.pdf','Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation')</script>
</i><br>
The Israeli Seminar on Computational Linguistics, <a href="http://www.cs.bgu.ac.il/~adlerm/iscol11/" target="_blank">ISCOL 2011</a> (06/2011)</li>


</ul>
</span>

<hr size=2 width="100%" align=center>
|
<a href="#top"> Top</a>
|
<a href="#short-bio"> Short Bio</a>
|
<a href="#news">News</a>
|
<a href="#publications">Publications</a>
|
<a href="#reviewing">Professional Activities</a>
| 
<a href="#code">Software and Resources</a>
| 
<a href="#teaching">Teaching</a>
|
<a href="#contact_info">Contact Info</a>
|
<hr size=2 width="100%" align=center>

<h2 class='h2_style'><a name=reviewing></a>Professional Activities</h2>
<ul>
<!--<li> Program committee member in <b>ACL</b> (<a href='http://acl2013.org/' target="_blank">2013</a>, <a href='http://www.cs.jhu.edu/ACL2014/' target="_blank">2014</a>, <a href='http://acl2015.org/' target="_blank">2015</a>, <a href='http://acl2016.org/' target="_blank">2016</a>, <a href='http://acl2017.org/' target="_blank">2017</a>), <b>EMNLP</b>  (<a href='http://hum.csse.unimelb.edu.au/emnlp2013/' target="_blank">2013</a>, <a href='http://www.emnlp2015.org/' target="_blank">2015</a>, <a href='http://www.emnlp2016.net/' target="_blank">2016</a>), <b>NAACL</b> (<a href='http://naacl.org/naacl-hlt-2016/' target="_blank">2016</a>), <b>CoNLL</b> (<a href='http://www.conll.org/' target="_blank">2016</a>), <b>EACL</b> (<a href='http://eacl2017.org/' target="_blank">2017</a>) and other NLP workshops.
<li> Reviewer for <b>EMNLP-CoNLL</b> (<a href='http://emnlp-conll2012.unige.ch/' target="_blank">2012</a>, <a href='http://emnlp2014.org/' target="_blank">2014</a>), <b>*SEM</b> (<a href='http://starsem.webhosting.rug.nl/wp/' target="_blank">2014</a>) </li>-->
<li> Program committee member for most major NLP conferences (ACL, EMNLP, NAACL, CoNLL, EACL), AAAI, and various NLP workshops</li>
<li>Reviewer for <a href="http://www.jair.org/" target="none;">JAIR</a>, <a href="https://www.cambridge.org/core/journals/natural-language-engineering" target="none;">Natural Language Engineering</a> and <a href="http://www.mdpi.com/journal/algorithms" target="none;">Algorithms</a></li>
</ul>


<hr size=2 width="100%" align=center>
|
<a href="#top"> Top</a>
|
<a href="#short-bio"> Short Bio</a>
|
<a href="#news">News</a>
|
<a href="#publications">Publications</a>
|
<a href="#talks">Talks</a>
| 
<a href="#code">Software and Resources</a>
| 
<a href="#teaching">Teaching</a>
|
<a href="#contact_info">Contact Info</a>
|
<hr size=2 width="100%" align=center>

<h2 class='h2_style'><a name=code></a>Software and Resources</h2>
<ul>
<li><script>URL(HOME,'papers/sp_sg/sp_sg.html','Skip-gram SP embeddings + code')</script>
&ndash; Skip-gram embeddings trained using symmetric pattern contexts plus the code for generating them</li>
	
<li><script>URL(HOME,'software/dr06/dr06.html','Symmetric Pattern Extraction')</script>
&ndash; Implementation of the Davidov & Rappoport (2006) algorithm for extracting symmetric patterns from plain text</li>

<li><script>URL(HOME,'papers/sp_embeddings/sp_embeddings.html','Symmetric pattern based word embeddings')</script>
&ndash; word embeddings based on symmetric patterns, designed to capture word similarity</li>

<li><script>URL(HOME,'papers/sp_embeddings/sp_embeddings.html','Antonymy as word analogy dataset')</script>
&ndash; dataset for evaluating the ability of word embeddings to capture antonyms</li>

<li><script>URL(HOME,'software/learnable.html','Most learnable dependency annotation scheme')</script>	
&ndash; a conversion tool from phrase structure annotation to the most learnable dependency annotation scheme</li>

<li><script>URL(HOME,'software/ned.html','NED')</script>	
&ndash; an unsupervised dependency parsing evaluation method</li>
</ul>

<hr size=2 width="100%" align=center>
|
<a href="#top"> Top</a>
|
<a href="#short-bio"> Short Bio</a>
|
<a href="#news">News</a>
|
<a href="#publications">Publications</a>
|
<a href="#talks"> Talks</a>
|
<a href="#reviewing">Professional Activities</a>
| 
<a href="#teaching">Teaching</a>
|
<a href="#contact_info">Contact Info</a>
|
<hr size=2 width="100%" align=center>

<h2 class='h2_style'><a name=teaching></a>Teaching</h2>

<ul>
<li> Guest talk on distributional semantics at UW NLP course (<a href="http://courses.cs.washington.edu/courses/csep517/17sp/slides/lecture8a.pdf" target="_blank">slides</a>, <a href="https://www.youtube.com/watch?v=cF6n_Gm05os" target="_blank">video</a>)
<li> UW-NLP RNN Reading Group (spring 2017)
<li> UW-NLP Discourse Reading Group (<a href="misc/discourse_reading_group.html" target="_blank">winter 2017</a>)
<li> Lecturer of the <a href="https://huji.coursera.org/oop-001" target="_blank"><b> huji coursera </b></a> online version of Introduction to Object Oriented Programming
<li> Lecturer of Introduction to Object Oriented Programming (<a href="http://moodle.cs.huji.ac.il/cs13/course/view.php?id=67125" target="_blank">13/14</a>, <a href="http://moodle.cs.huji.ac.il/cs11/course/view.php?id=67125" target="_blank">11/12</a> <font color='red'><b>[Ranked #1 in student survey!]</b></font>, 
<a href="http://moodle.cs.huji.ac.il/cs10/course/view.php?id=67125" target="_blank">10/11</a>,
<a href="http://moodle.cs.huji.ac.il/cs09/course/view.php?id=67125" target="_blank">09/10</a>) <br>
 </li>
<li> Lecturer of Computer Laboratory in Data Structures (<a href="http://moodle.cs.huji.ac.il/cs12/course/view.php?id=67125" target="_blank">12/13</a>) </li>
<li> Lecturer of Introduction to Programming in the Perl Language (<a href="http://moodle.cs.huji.ac.il/old/course/view.php?id=105" target="_blank">07/08</a>)</li>
 </ul>


<hr size=2 width="100%" align=center>
|
<a href="#top"> Top</a>
|
<a href="#short-bio"> Short Bio</a>
|
<a href="#news">News</a>
|
<a href="#publications">Publications</a>
|
<a href="#talks"> Talks</a>
|
<a href="#reviewing">Professional Activities</a>
| 
<a href="#code">Software and Resources</a>
| 
<a href="#contact_info">Contact Info</a>
|
<hr size=2 width="100%" align=center>

<h2 class='h2_style'><a name="contact_info"></a>Contact Info</h2>

<p>Roy
Schwartz<br>
<a href="http://www.cs.washington.edu/" target="_blank">Paul G. Allen Center for Computer Science & Engineering</a>, Room 338<br>
<a href=http://www.washington.edu/ target="_blank">University of Washington</a> <br>
185 Stevens Way<br>
Seattle, Washington,  98195-2350<br>
<br>
<script>email()</script>
<hr size=2 width="100%" align=center>

<p>
|
<a href="#top">Top</a>
|
<a href="#short-bio">Short Bio</a>
|
<a href="#news">News</a>
|
<a href="#publications">Publications</a>
|
<a href="#talks"> Talks</a>
|
<a href="#reviewing">Professional Activities</a>
| 
<a href="#code">Software and Resources</a>
| 
<a href="#teaching">Teaching</a>
|


<hr size=2 width="100%" align=center>
<!--ministat.org -->
<noscript><a href='http://ministat.org/' title='ministat liczniki.org' target="_blank">
<img style='border: 0px' alt="visit counter" src='http://ministat.org/ms2.php?l=roy'><br>ministat liczniki.org</a></noscript>
<script type='text/javascript' src='http://ministat.org/ms2js.php?l=roy&amp;js=1'></script>
<!--end of ministat.org code-->

Last update: 03/2018



</body>

</html>
