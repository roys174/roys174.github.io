<!DOCTYPE html>
<html>

<head>
<meta name="viewport" content="width=device-width">
<script type="text/javascript" src="../../import.js"></script> 
<link href='http://fonts.googleapis.com/css?family=Cabin:600|Nunito:400,300' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="../../styles.css" type="text/css">
<title>Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing</title>
 <meta name="citation_title" content="Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing" /> 
 <meta name="citation_publication_date" content="2011" /> 
 <meta name="citation_author" content="Schwartz, Roy" /> 
 <meta name="citation_author" content="Abend, Omri" />
 <meta name="citation_author" content="Reichart, Roi" /> 
 <meta name="citation_author" content="Rappoport, Ari" />   
 <meta name="citation_conference_title" content="In proceedings of ACL 2011" />
  <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22481028-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>

<body lang=EN-US>

<div class=WordSection1>

<h1 class=page_titles>Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing</h1>

    <script>document.write(ME_LINK+", "+OMRI+", "+ROI+" and "+ARI)</script><br>

In proceedings of <a href="http://www.acl2011.org/" target="_blank">ACL 2011</a> (long paper) 
<br>
[<script>URL(HOME,'papers/ned/ned_camera_ready.pdf','pdf')</script>]
[<script>URL(HOME,'papers/ned/ned_acl_slides.pdf','slides')</script>]
[<script>URL(HOME,'papers/ned/ned.bib','bib')</script>]
[<script>URL(HOME,'software/ned.html','code', "style='color:red'")</script>]

<br><br>


Abstract:<br>
Dependency parsing is a central NLP task. In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations. We show that for three leading unsupervised parsers (Klein and Manning, 2004; Cohen and Smith, 2009; Spitkovsky et al., 2010a), a small set of parameters can be found whose modification yields a significant improvement in standard evaluation measures. These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation. Therefore, the standard evaluation does not provide a true indication of algorithm quality. We present a new measure, Neutral Edge Direction (NED), and show that it greatly reduces this undesired phenomenon.

</div>

<br><br>
For any questions or feedback, please email<br><script>email()</script>

    
</body>

</html>
