<head>

</head>

<body>
        I devise mathematical theories that link deep neural models to classical NLP models, such as weighted finite-state automata.
        As the theory behind the latter is well studied, this new understanding {al}lows for the development of {\bf more interpretable} and {\bf better-performing} NLP models.
        Another research approach I follow is analyzing the datasets on which NLP models are trained. %, and treating them as black boxes, querying them with different tasks.
        Looking carefully into these datasets, I uncover \emph{limitations} and \emph{biases} in the data collection process as well as the evaluation process (\secref{artifacts}).
        My findings indicate that the recent success of neural models on many NLP tasks has been {\bf overestimated}, and  pave the way for the development of {\bf more reliable} methods of evaluation.
        %I also enhance NLP models with linguistic information, making them 
        I also run {\bf linguistic analysis} on representations learned from neural networks applied to NLP. 
        My work shows that neural models for NLP are {\bf failing to encode} important types of semantic knowledge.
        Based on these observations, I present methods that inject linguistic knowledge into NLP models, directly improving them (\secref{embeddings}).

</body>