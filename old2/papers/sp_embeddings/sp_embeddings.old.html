<!DOCTYPE html>
<html>

<head>
<link href='http://fonts.googleapis.com/css?family=Cabin:600|Nunito:400,300' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="http://www.cs.huji.ac.il/~roys02/styles.css" type="text/css">
<title>Symmetric Pattern Based Word Embeddings for Improved Word Similarity Prediction</title>
 <meta name="citation_title" content="Symmetric Pattern Based Word Embeddings for Improved Word Similarity Prediction" /> 
 <meta name="citation_publication_date" content="2015" /> 
 <meta name="citation_author" content="Schwartz, Roy" /> 
 <meta name="citation_author" content="Reichart, Roi" />
 <meta name="citation_author" content="Rappoport, Ari" />   
 <meta name="citation_conference_title" content="In proceedings of CoNLL 2015" />
 <meta name="citation_pdf_url" content="http://www.cs.huji.ac.il/~roys02/papers/sp_embeddings/sp_embeddings_conll.pdf" /> 
 
 <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22481028-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>

<body lang=EN-US>

<div class=WordSection1>

<h1 class=page_titles>Symmetric Pattern Based Word Embeddings for Improved Word Similarity Prediction</h1>

<a href="http://www.cs.huji.ac.il/~roys02">Roy Schwartz</a>, <a href="http://ie.technion.ac.il/~roiri/" target="_blank">Roi Reichart</a>
and <a href="http://www.cs.huji.ac.il/~arir" target="_blank">Ari Rappoport</a><br>
To appear in <a href='http://www.conll.org/2015' target="_blank">CoNLL 2015</a> (long paper) <br>
[<a href="http://www.cs.huji.ac.il/~roys02/papers/sp_embeddings/sp_embeddings_conll.pdf" onclick="pageTracker._trackPageview('http://www.cs.huji.ac.il/~roys02/papers/sp_embeddings/sp_embeddings_conll.pdf');">pdf</a>]
[<a href='http://www.cs.huji.ac.il/~roys02/papers/sp_embeddings/sp_embeddings.bib' target="_blank">bib</a>] 
[<a href="http://www.cs.huji.ac.il/~roys02/papers/sp_embeddings/antonymy_analogy_questions.zip"><span style='color:green'>dataset</span></a>]
<br><br>

Abstract:<br>
We present a novel word level vector representation based on symmetric patterns (SPs). For this aim we automatically acquire SPs (e.g., "X and Y") from a large corpus of plain text, and generate vectors where each coordinate represents the co-occurrence in SPs of the represented word with another word of the vocabulary. Our representation has three advantages over existing alternatives: First, being based on symmetric word relationships, it is highly suitable for word similarity prediction. Particularly, on the SimLex999 word similarity dataset, our model achieves a Spearman's &#961; score of 0.517, compared to 0.462 of the state-of-the-art word2vec model. Interestingly, our model performs exceptionally well on verbs, outperforming stat-eof-the-art baselines by 20.2&#x2012;41.5%. Second, pattern features can be adapted to the needs of a target NLP application. For example, we show that we can easily control whether the embeddings derived from SPs deem antonym pairs (e.g. (big,small)) as similar or dissimilar, an important distinction for tasks such as word classification and sentiment analysis. Finally, we show that a simple combination of the word similarity scores generated by our method and by word2vec results in a superior predictive power over that of each individual model, scoring as high as 0.563 in Spearman's &#961; on SimLex999. This emphasizes the differences between the signals captured by each of the models.
</div>
</body>

</html>
